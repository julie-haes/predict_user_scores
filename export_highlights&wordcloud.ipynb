{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import subprocess as SB\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'nixon_single.csv' does not exist: b'nixon_single.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-855a219dabaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nixon_single.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'nixon_single.csv' does not exist: b'nixon_single.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('nixon_single.csv', sep='\\t', encoding = 'utf-8')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HELPERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Returns the result of the method evaluate(...), which is the middle part of the html\n",
    "    @text_review: The original text review\n",
    "    @shap_string The shap (json) information as a string\n",
    "\"\"\"\n",
    "def getMiddle(text_review, shap_string):\n",
    "    result = evaluate(text_review, shap_string)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Turns a string into JSON\n",
    "    @shap_string : The shap (json) information as a string\n",
    "\"\"\"\n",
    "def parseShap(shap_string):\n",
    "    return json.loads(shap_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Checks if a word has a shap value\n",
    "    @list : Shap information\n",
    "    @term : A term as it appears in the original review text\n",
    "\"\"\"\n",
    "def find_dictionary(list, term):    \n",
    "    for x in range(0, len(list)):\n",
    "        if (list[x]['term'] == term.lower()) or (term[0:-1].lower() == list[x]['term'] and term[-1] == 's'):\n",
    "            return list[x]\n",
    "        elif (term[-3:] == \"n't\" and term[0:-2].lower() == list[x]['term']):\n",
    "            return list[x]\n",
    "        elif (term.lower() == \"watches\") and (list[x]['term'] == 'watch'):\n",
    "            return list[x]\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Returns the html code with highlights around \n",
    "    @input : the original review text\n",
    "    @shap : the shap json, containing shap information for the review text\n",
    "\"\"\"\n",
    "def evaluate(input, shap):\n",
    "    parts = custom_split(input)\n",
    "    output = \"\"\n",
    "    for part in parts:\n",
    "        parse = parseShap(shap)\n",
    "        s = find_dictionary(parse, part)\n",
    "        if s is not None:\n",
    "            element = invoke_paragraph(s, part)\n",
    "            output = output + element\n",
    "        else: output = output + part\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Returns the review text split in parts based on special signs\n",
    "\"\"\"\n",
    "def custom_split(input):\n",
    "    array = ['.', '?', '!', ',', ' ', '-', '\"']\n",
    "    result = []\n",
    "    length = len(input)\n",
    "\n",
    "    word = ''\n",
    "\n",
    "    for i in range(len(input)):\n",
    "        char = input[i]\n",
    "        if char in array:\n",
    "            if word != '' :\n",
    "                result.append(word)\n",
    "                word = \"\"\n",
    "            result.append(char)\n",
    "        else:\n",
    "            word += char\n",
    "            \n",
    "    if word != ' ' : \n",
    "        result.append(word)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_paragraph(dictionary, part):\n",
    "    factor = dictionary['factor']\n",
    "    identifier = dictionary['id']\n",
    "    orientation = dictionary['orientation']\n",
    "        \n",
    "    return highlight_part(factor, identifier, orientation, part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Creates a text highlighting and returns the html code for the text highlighting\n",
    "\"\"\"\n",
    "def highlight_part(shapvalue, identifier, orientation, term) :\n",
    "    factor = round(abs(shapvalue),2)\n",
    "    orientation = lambda x : \"positive\" if (x > 0) else \"negative\"\n",
    "    \n",
    "    return \"<span class=\\\"highlighter \" + identifier + \"\\\" data-shap=\\\"\" + str(factor) + \"\\\" data-orientation=\\\"\" + orientation(shapvalue) + \"\\\">\" + term + \"</span>\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOrientation(shap_json):\n",
    "    empty = {}\n",
    "    for el in shap_json:\n",
    "        term = el['term']\n",
    "        orientation = el['orientation']\n",
    "        empty[term] = orientation\n",
    "    return empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIDs(shap_json):\n",
    "    empty = {}\n",
    "    for el in shap_json:\n",
    "        term = el['term']\n",
    "        identifier = el['id']\n",
    "        empty[term] = identifier\n",
    "    return empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFactors(shap_json):\n",
    "    empty = {}\n",
    "    for el in shap_json:\n",
    "        term = el[\"term\"]\n",
    "        factor = el[\"factor\"]\n",
    "        empty[term] = factor\n",
    "    return empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOccurrence(shap_json):\n",
    "    empty = {}\n",
    "    for el in shap_json:\n",
    "        term = el[\"term\"]\n",
    "        factor = el[\"occurrence\"]\n",
    "        empty[term] = factor\n",
    "    return empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERATE INPUT FILE cloud.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createInputFile(factors, occurrences, filename):\n",
    "    file = filename + \".txt\"\n",
    "    words = \"\"\n",
    "    for key in factors:\n",
    "        occ = occurrences[key]\n",
    "        if (occ != 0):\n",
    "            v = factors[key]\n",
    "            size = (float(v) * 100)    \n",
    "            for i in range(1, int(size)):\n",
    "                words += key + \" \"\n",
    "            words += \". \"\n",
    "\n",
    "    with open(file, \"w\") as text_file:\n",
    "        text_file.write(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERATE SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSVG(filename):\n",
    "    file = filename + \".txt\"\n",
    "    args = ['java', '-jar', 'cloudy.jar', '-w1200', '-h500', '-Lmds', '-ps', '-pg', '-pn', '-O', file]\n",
    "    SB.call(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARSE SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseSVG(filename, ids, orientations):\n",
    "    file = filename + \".svg\"\n",
    "    root = ET.parse(file).getroot()\n",
    "    internal = root[1]\n",
    "    result = '<svg width=\"500\" height=\"275\" font-family=\"Arial\" fill=\"#a9a9a9\" font-style=\"normal\" font-weight=\"bold\"> <g transform=\"scale(0.5)\">'\n",
    "\n",
    "    for child in internal:\n",
    "        attributes = child.attrib\n",
    "        term = child[0]\n",
    "\n",
    "        transform = attributes['transform']\n",
    "        x = term.attrib['x']\n",
    "        y = term.attrib['y']\n",
    "        size = attributes['font-size']\n",
    "        text = term.text\n",
    "        orientation = orientations[term.text]\n",
    "\n",
    "        fill = 'black'\n",
    "        if (orientation == 'positive'):\n",
    "            fill = 'rgb(44, 160, 44)'\n",
    "        elif (orientation == 'negative'):\n",
    "            fill = 'rgb(214, 39, 40)'\n",
    "\n",
    "        id_tag = ids[term.text]\n",
    "        new_tag = '<g transform=\"' + transform + '\" font-size=\"' + str(size) + '\" fill=\"' + fill + '\" onclick=\"highlight(`' + id_tag + '`, `' + orientation + '`)' +'\">' + '<text x=\"' + x + '\" y=\"' + y + '\">' + term.text + '</text></g>'\n",
    "        result = result + new_tag\n",
    "    result = result + '</g></svg>'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN SCRIPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "filename = \"test_cloud\"\n",
    "html_col = []\n",
    "\n",
    "header = '<p id=\"review_text\" class=\"review_result\">'\n",
    "footer = '</p>'\n",
    "\n",
    "for i in data.index:\n",
    "    row = data.loc[i]\n",
    "    \n",
    "    # SETUP\n",
    "    shap = row.Shap_json    \n",
    "    review_text = row.Review\n",
    "       \n",
    "    # HIGHLIGHTS IN REVIEW TEXT\n",
    "    middle = getMiddle(review_text, shap)\n",
    "    html = header + middle + footer\n",
    "    html_col.append(html)\n",
    "        \n",
    "    # CREATE INPUT FILE (word cloud)\n",
    "    s = json.loads(shap)\n",
    "    factors = getFactors(s)\n",
    "    occurrences = getOccurrence(s)\n",
    "    createInputFile(factors, occurrences, filename)\n",
    "    \n",
    "    # CREATE WORD CLOUDS\n",
    "    generateSVG(filename)\n",
    "    orientations = getOrientation(s)\n",
    "    ids = getIDs(s)\n",
    "    result = parseSVG(filename, ids, orientations)\n",
    "    result_list.append(result)\n",
    "    \n",
    "    # RESET\n",
    "    shap = \"\"\n",
    "    review_text = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Highlights\"] = html_col\n",
    "data[\"Cloud\"] = result_list\n",
    "del data['Prediction']\n",
    "del data['Shap_json']\n",
    "\n",
    "data.to_csv('nixon_html.csv', sep='\\t', index=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_json('nixon.json', orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
